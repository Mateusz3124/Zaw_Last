{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqpfmA2Pjmyl",
        "outputId": "be6b3700-9959-4d19-c0cf-2defc21a29c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvcc4jupyter\n",
            "  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install nvcc4jupyter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYbQmoS7jryX",
        "outputId": "192b4aa8-a7aa-4a39-d402-36ffbea84750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmpksoi5hob\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix-multiplication.cu\n",
        "// Code from: https://gist.github.com/jarvisnn/c211e44af9f4334fdb0c245ae9ca9f8a\n",
        "/**\n",
        " *\n",
        " * Matrix Multiplication - CUDA for GPUs\n",
        " *\n",
        " * NUS CS3210 - Jarvis\n",
        " *\n",
        " **/\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <sys/time.h>\n",
        "#include <assert.h>\n",
        "\n",
        "// Block Size\n",
        "#define BLOCK_SIZE 32\n",
        "\n",
        "int size;\n",
        "\n",
        "typedef struct\n",
        "{\n",
        "\tfloat ** element;\n",
        "} matrix;\n",
        "\n",
        "\n",
        "long long wall_clock_time()\n",
        "{\n",
        "#ifdef __linux__\n",
        "\tstruct timespec tp;\n",
        "\tclock_gettime(CLOCK_REALTIME, &tp);\n",
        "\treturn (long long)(tp.tv_nsec + (long long)tp.tv_sec * 1000000000ll);\n",
        "#else\n",
        "\tstruct timeval tv;\n",
        "\tgettimeofday(&tv, NULL);\n",
        "\treturn (long long)(tv.tv_usec * 1000 + (long long)tv.tv_sec * 1000000000ll);\n",
        "#endif\n",
        "}\n",
        "\n",
        "/**\n",
        " * Allocates memory for a matrix of size SIZE\n",
        " * The memory is allocated row-major order, i.e.\n",
        " *  elements from the same row are allocated at contiguous\n",
        " *  memory addresses.\n",
        " **/\n",
        "void allocate_matrix(matrix* m)\n",
        "{\n",
        "\tint i;\n",
        "\tcudaError_t rc;\n",
        "\n",
        "\t// allocate array for all the rows\n",
        "\trc = cudaMallocManaged((void**)&(m->element), sizeof(float*) * size);\n",
        "\tif (rc != cudaSuccess)\n",
        "\t{\n",
        "\t\tfprintf(stderr, \"CUDA error: %s\\n\", cudaGetErrorString(rc));\n",
        "\t\texit(1);\n",
        "\t}\n",
        "\n",
        "\t// allocate an array for each row of the matrix\n",
        "\tfor (i = 0; i < size; i++)\n",
        "\t{\n",
        "\t\trc = cudaMallocManaged((void**)&(m->element[i]), sizeof(float) * size);\n",
        "\t\tif (rc != cudaSuccess)\n",
        "\t\t{\n",
        "\t\t\tfprintf(stderr, \"CUDA error: %s\\n\", cudaGetErrorString(rc));\n",
        "\t\t\texit(1);\n",
        "\t\t}\n",
        "\t}\n",
        "}\n",
        "\n",
        "/**\n",
        " * Free the memory allocated for a matrix.\n",
        " **/\n",
        "void free_matrix(matrix* m) {\n",
        "\tint i;\n",
        "\tfor (i = 0; i < size; i++)\n",
        "\t\tcudaFree(m->element[i]);\n",
        "\tcudaFree(m->element);\n",
        "}\n",
        "\n",
        "/**\n",
        " * Initializes the elements of the matrix with\n",
        " * random values between 0 and 9\n",
        " **/\n",
        "void init_matrix(matrix m)\n",
        "{\n",
        "\tint i, j;\n",
        "\n",
        "\tfor (i = 0; i < size; i++)\n",
        "\t\tfor (j = 0; j < size; j++)\n",
        "\t\t{\n",
        "\t\t\tm.element[i][j] = rand() % 10;\n",
        "\t\t}\n",
        "}\n",
        "\n",
        "/**\n",
        " * Initializes the elements of the matrix with\n",
        " * element 0.\n",
        " **/\n",
        "void init_matrix_zero(matrix m)\n",
        "{\n",
        "\tint i, j;\n",
        "\n",
        "\tfor (i = 0; i < size; i++)\n",
        "\t\tfor (j = 0; j < size; j++)\n",
        "\t\t{\n",
        "\t\t\tm.element[i][j] = 0.0;\n",
        "\t\t}\n",
        "}\n",
        "\n",
        "\n",
        "/**\n",
        " * Multiplies matrix @a with matrix @b storing\n",
        " * the result in matrix @result\n",
        " *\n",
        " * The multiplication algorithm is the O(n^3)\n",
        " * algorithm\n",
        " */\n",
        "void mm(matrix a, matrix b, matrix result)\n",
        "{\n",
        "\tint i, j, k;\n",
        "\n",
        "\t// Do the multiplication\n",
        "\tfor (i = 0; i < size; i++)\n",
        "\t\tfor (j = 0; j < size; j++)\n",
        "\t\t\tfor(k = 0; k < size; k++)\n",
        "\t\t\t\tresult.element[i][j] += a.element[i][k] * b.element[k][j];\n",
        "}\n",
        "\n",
        "/**\n",
        " * Each kernel computes the result element (i,j).\n",
        " */\n",
        "__global__ void mm_kernel(matrix a, matrix b, matrix result, int size)\n",
        "{\n",
        "\t// Block Index and Thread Index\n",
        "\tint bx = blockIdx.x;\n",
        "\tint by = blockIdx.y;\n",
        "\tint tx = threadIdx.x;\n",
        "\tint ty = threadIdx.y;\n",
        "\n",
        "\t// Current cell to be calculated (result[cx][cy]);\n",
        "\tint cx = bx * BLOCK_SIZE + tx;\n",
        "\tint cy = by * BLOCK_SIZE + ty;\n",
        "\n",
        "\t// Variables\n",
        "\tint blkStart, k;\n",
        "\n",
        "\t// Variable to store the value of result[cx][cy]\n",
        "\tfloat c = 0;\n",
        "\n",
        "\t// Go through sub-matrices a[BLOCK_SIZE][size] and b[size, BLOCK_SIZE]\n",
        "\t// Do not load all at one time. Load these sub-matrices by block (sub-sub-matrices) of size (BLOCK_SIZE, BLOCK_SIZE).\n",
        "\tfor (blkStart = 0; blkStart < size; blkStart += BLOCK_SIZE) {\n",
        "\n",
        "\t\t// Shared mem for the sub-sub-matrices of a and b\n",
        "\t\t__shared__ float a_sub[BLOCK_SIZE][BLOCK_SIZE];\n",
        "\t\t__shared__ float b_sub[BLOCK_SIZE][BLOCK_SIZE];\n",
        "\n",
        "\t\t// Load sub-sub-matrices, each thread load 1 cell only\n",
        "\t\ta_sub[tx][ty] = (cx < size && blkStart + ty < size) ? a.element[cx][blkStart + ty] : 0;\n",
        "\t\tb_sub[tx][ty] = (blkStart + tx < size && cy < size) ? b.element[blkStart + tx][cy] : 0;\n",
        "\n",
        "\t\t// Make sure all data is loaded.\n",
        "\t\t__syncthreads();\n",
        "\n",
        "\t\t// For-loop to calculate the value of result[cx][cy] by 2 sub-sub-matrices.\n",
        "\t\t// Unroll is a minor improvement of Cuda for simple for-loop.\n",
        "\t\t#pragma unroll\n",
        "\t\tfor (k = 0; k < BLOCK_SIZE; k++) {\n",
        "\t\t\tc += a_sub[tx][k] * b_sub[k][ty];\n",
        "\t\t}\n",
        "\n",
        "\t\t// Make sure all computations are done before the next phase.\n",
        "\t\t__syncthreads();\n",
        "\t}\n",
        "\n",
        "\t// Verify the cell, add to the result.\n",
        "\tif (cx >= size || cy >= size) return;\n",
        "\tresult.element[cx][cy] = c;\n",
        "}\n",
        "\n",
        "void print_matrix(matrix m)\n",
        "{\n",
        "\tint i, j;\n",
        "\n",
        "\tfor (i = 0; i < size; i++)\n",
        "\t{\n",
        "\t\tprintf(\"row %4d: \", i);\n",
        "\t\tfor (j = 0; j < size; j++)\n",
        "\t\t\tprintf(\"%6.2f  \", m.element[i][j]);\n",
        "\t\tprintf(\"\\n\");\n",
        "\t}\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "void work()\n",
        "{\n",
        "\tmatrix a, b, result1, result2;\n",
        "\tlong long before, after;\n",
        "\tint correct, i, j, dim;\n",
        "\tcudaError_t rc;\n",
        "\n",
        "\t// Allocate memory for matrices\n",
        "\tallocate_matrix(&a);\n",
        "\tallocate_matrix(&b);\n",
        "\tallocate_matrix(&result1);\n",
        "\tallocate_matrix(&result2);\n",
        "\n",
        "\t// Initialize matrix elements\n",
        "\tinit_matrix(a);\n",
        "\tinit_matrix(b);\n",
        "\n",
        "\t// Perform sequential matrix multiplication\n",
        "\tbefore = wall_clock_time();\n",
        "\tmm(a, b, result1);\n",
        "\tafter = wall_clock_time();\n",
        "        fprintf(stderr, \"Matrix multiplication on CPU took %1.2f seconds\\n\", ((float)(after - before))/1000000000);\n",
        "\n",
        "\t// Perform CUDA matrix  multiplication\n",
        "\tdim3 block(BLOCK_SIZE, BLOCK_SIZE);\t\t\t// a block of BLOCK_SIZE x BLOCK_SIZE CUDA threads\n",
        "\tdim = (size % BLOCK_SIZE == 0) ? size / BLOCK_SIZE : size / BLOCK_SIZE + 1;\n",
        "\tdim3 grid(dim, dim);\t\t\t\t\t\t// a grid of CUDA thread blocks\n",
        "\tbefore = wall_clock_time();\n",
        "\tmm_kernel<<<grid, block>>>(a, b, result2, size);\n",
        "\tcudaDeviceSynchronize();\n",
        "\tafter = wall_clock_time();\n",
        "\tfprintf(stderr, \"Matrix multiplication on GPU took %1.2f seconds\\n\", ((float)(after - before))/1000000000);\n",
        "\n",
        "\t// was there any error?\n",
        "        rc = cudaGetLastError();\n",
        "        if (rc != cudaSuccess)\n",
        "                printf(\"Last CUDA error %s\\n\", cudaGetErrorString(rc));\n",
        "\n",
        "\t// Compare the results\n",
        "\tcorrect = 1;\n",
        "\tfor (i = 0; correct && i < size; i++)\n",
        "\t\tfor (j = 0; j < size; j++)\n",
        "\t\t\tif (result1.element[i][j] != result2.element[i][j]) {\n",
        "\t\t\t\tcorrect = 0;\n",
        "\t\t\t\tbreak;\n",
        "\t\t\t}\n",
        "\n",
        "\tif (correct)\n",
        "\t\tprintf(\"The result matrices are identical!\\n\");\n",
        "\telse\n",
        "\t\tprintf(\"Difference in result matrices at element (%d, %d)!\\n\", i, j);\n",
        "\n",
        "\tfree_matrix(&a);\n",
        "\tfree_matrix(&b);\n",
        "\tfree_matrix(&result1);\n",
        "\tfree_matrix(&result2);\n",
        "}\n",
        "\n",
        "\n",
        "int main(int argc, char ** argv)\n",
        "{\n",
        "\tsrand(0);\n",
        "\n",
        "\tprintf(\"Usage: %s <size>\\n\", argv[0]);\n",
        "\n",
        "\tif (argc >= 2)\n",
        "\t\tsize = atoi(argv[1]);\n",
        "\telse\n",
        "\t\tsize = 1024;\n",
        "\n",
        "\tfprintf(stderr,\"Sequential matrix multiplication of size %d\\n\", size);\n",
        "\n",
        "\t// Multiply the matrices\n",
        "\twork();\n",
        "\n",
        "\treturn 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEdxQuHojzg4",
        "outputId": "ebdcf54d-94cb-42e1-a747-20b4bb4aa565"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matrix-multiplication.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile transpose.cu\n",
        "// https://github.com/NVIDIA-developer-blog/code-samples/blob/master/series/cuda-cpp/transpose/transpose.cu\n",
        "/* Copyright (c) 1993-2015, NVIDIA CORPORATION. All rights reserved.\n",
        " *\n",
        " * Redistribution and use in source and binary forms, with or without\n",
        " * modification, are permitted provided that the following conditions\n",
        " * are met:\n",
        " *  * Redistributions of source code must retain the above copyright\n",
        " *    notice, this list of conditions and the following disclaimer.\n",
        " *  * Redistributions in binary form must reproduce the above copyright\n",
        " *    notice, this list of conditions and the following disclaimer in the\n",
        " *    documentation and/or other materials provided with the distribution.\n",
        " *  * Neither the name of NVIDIA CORPORATItransposeON nor the names of its\n",
        " *    contributors may be used to endorse or promote products derived\n",
        " *    from this software without specific prior written permission.\n",
        " *\n",
        " * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY\n",
        " * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
        " * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\n",
        " * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR\n",
        " * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,\n",
        " * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,\n",
        " * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\n",
        " * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY\n",
        " * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n",
        " * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
        " * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
        " */\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <assert.h>\n",
        "\n",
        "// Convenience function for checking CUDA runtime API results\n",
        "// can be wrapped around any runtime API call. No-op in release builds.\n",
        "inline\n",
        "cudaError_t checkCuda(cudaError_t result)\n",
        "{\n",
        "#if defined(DEBUG) || defined(_DEBUG)\n",
        "  if (result != cudaSuccess) {\n",
        "    fprintf(stderr, \"CUDA Runtime Error: %s\\n\", cudaGetErrorString(result));\n",
        "    assert(result == cudaSuccess);\n",
        "  }\n",
        "#endif\n",
        "  return result;\n",
        "}\n",
        "\n",
        "const int TILE_DIM = 32;\n",
        "const int BLOCK_ROWS = 8;\n",
        "const int NUM_REPS = 100;\n",
        "\n",
        "// Check errors and print GB/s\n",
        "void postprocess(const float *ref, const float *res, int n, float ms)\n",
        "{\n",
        "  bool passed = true;\n",
        "  for (int i = 0; i < n; i++)\n",
        "    if (res[i] != ref[i]) {\n",
        "      printf(\"%d %f %f\\n\", i, res[i], ref[i]);\n",
        "      printf(\"%25s\\n\", \"*** FAILED ***\");\n",
        "      passed = false;\n",
        "      break;\n",
        "    }\n",
        "  if (passed)\n",
        "    printf(\"%20.2f\\n\", 2 * n * sizeof(float) * 1e-6 * NUM_REPS / ms );\n",
        "}\n",
        "\n",
        "// simple copy kernel\n",
        "// Used as reference case representing best effective bandwidth.\n",
        "__global__ void copy(float *odata, const float *idata)\n",
        "{\n",
        "  int x = blockIdx.x * TILE_DIM + threadIdx.x;\n",
        "  int y = blockIdx.y * TILE_DIM + threadIdx.y;\n",
        "  int width = gridDim.x * TILE_DIM;\n",
        "\n",
        "  for (int j = 0; j < TILE_DIM; j+= BLOCK_ROWS)\n",
        "    odata[(y+j)*width + x] = idata[(y+j)*width + x];\n",
        "}\n",
        "\n",
        "// copy kernel using shared memory\n",
        "// Also used as reference case, demonstrating effect of using shared memory.\n",
        "__global__ void copySharedMem(float *odata, const float *idata)\n",
        "{\n",
        "  __shared__ float tile[TILE_DIM * TILE_DIM];\n",
        "\n",
        "  int x = blockIdx.x * TILE_DIM + threadIdx.x;\n",
        "  int y = blockIdx.y * TILE_DIM + threadIdx.y;\n",
        "  int width = gridDim.x * TILE_DIM;\n",
        "\n",
        "  for (int j = 0; j < TILE_DIM; j += BLOCK_ROWS)\n",
        "     tile[(threadIdx.y+j)*TILE_DIM + threadIdx.x] = idata[(y+j)*width + x];\n",
        "\n",
        "  __syncthreads();\n",
        "\n",
        "  for (int j = 0; j < TILE_DIM; j += BLOCK_ROWS)\n",
        "     odata[(y+j)*width + x] = tile[(threadIdx.y+j)*TILE_DIM + threadIdx.x];\n",
        "}\n",
        "\n",
        "// naive transpose\n",
        "// Simplest transpose; doesn't use shared memory.\n",
        "// Global memory reads are coalesced but writes are not.\n",
        "__global__ void transposeNaive(float *odata, const float *idata)\n",
        "{\n",
        "  int x = blockIdx.x * TILE_DIM + threadIdx.x;\n",
        "  int y = blockIdx.y * TILE_DIM + threadIdx.y;\n",
        "  int width = gridDim.x * TILE_DIM;\n",
        "\n",
        "  for (int j = 0; j < TILE_DIM; j+= BLOCK_ROWS)\n",
        "    odata[x*width + (y+j)] = idata[(y+j)*width + x];\n",
        "}\n",
        "\n",
        "// coalesced transpose\n",
        "// Uses shared memory to achieve coalesing in both reads and writes\n",
        "// Tile width == #banks causes shared memory bank conflicts.\n",
        "__global__ void transposeCoalesced(float *odata, const float *idata)\n",
        "{\n",
        "  __shared__ float tile[TILE_DIM][TILE_DIM];\n",
        "\n",
        "  int x = blockIdx.x * TILE_DIM + threadIdx.x;\n",
        "  int y = blockIdx.y * TILE_DIM + threadIdx.y;\n",
        "  int width = gridDim.x * TILE_DIM;\n",
        "\n",
        "  for (int j = 0; j < TILE_DIM; j += BLOCK_ROWS)\n",
        "     tile[threadIdx.y+j][threadIdx.x] = idata[(y+j)*width + x];\n",
        "\n",
        "  __syncthreads();\n",
        "\n",
        "  x = blockIdx.y * TILE_DIM + threadIdx.x;  // transpose block offset\n",
        "  y = blockIdx.x * TILE_DIM + threadIdx.y;\n",
        "\n",
        "  for (int j = 0; j < TILE_DIM; j += BLOCK_ROWS)\n",
        "     odata[(y+j)*width + x] = tile[threadIdx.x][threadIdx.y + j];\n",
        "}\n",
        "\n",
        "\n",
        "// No bank-conflict transpose\n",
        "// Same as transposeCoalesced except the first tile dimension is padded\n",
        "// to avoid shared memory bank conflicts.\n",
        "__global__ void transposeNoBankConflicts(float *odata, const float *idata)\n",
        "{\n",
        "  __shared__ float tile[TILE_DIM][TILE_DIM+1];\n",
        "\n",
        "  int x = blockIdx.x * TILE_DIM + threadIdx.x;\n",
        "  int y = blockIdx.y * TILE_DIM + threadIdx.y;\n",
        "  int width = gridDim.x * TILE_DIM;\n",
        "\n",
        "  for (int j = 0; j < TILE_DIM; j += BLOCK_ROWS)\n",
        "     tile[threadIdx.y+j][threadIdx.x] = idata[(y+j)*width + x];\n",
        "\n",
        "  __syncthreads();\n",
        "\n",
        "  x = blockIdx.y * TILE_DIM + threadIdx.x;  // transpose block offset\n",
        "  y = blockIdx.x * TILE_DIM + threadIdx.y;\n",
        "\n",
        "  for (int j = 0; j < TILE_DIM; j += BLOCK_ROWS)\n",
        "     odata[(y+j)*width + x] = tile[threadIdx.x][threadIdx.y + j];\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "  const int nx = 1024;\n",
        "  const int ny = 1024;\n",
        "  const int mem_size = nx*ny*sizeof(float);\n",
        "\n",
        "  dim3 dimGrid(nx/TILE_DIM, ny/TILE_DIM, 1);\n",
        "  dim3 dimBlock(TILE_DIM, BLOCK_ROWS, 1);\n",
        "\n",
        "  int devId = 0;\n",
        "  if (argc > 1) devId = atoi(argv[1]);\n",
        "\n",
        "  cudaDeviceProp prop;\n",
        "  checkCuda( cudaGetDeviceProperties(&prop, devId));\n",
        "  printf(\"\\nDevice : %s\\n\", prop.name);\n",
        "  printf(\"Matrix size: %d %d, Block size: %d %d, Tile size: %d %d\\n\",\n",
        "         nx, ny, TILE_DIM, BLOCK_ROWS, TILE_DIM, TILE_DIM);\n",
        "  printf(\"dimGrid: %d %d %d. dimBlock: %d %d %d\\n\",\n",
        "         dimGrid.x, dimGrid.y, dimGrid.z, dimBlock.x, dimBlock.y, dimBlock.z);\n",
        "\n",
        "  checkCuda( cudaSetDevice(devId) );\n",
        "\n",
        "  float *h_idata = (float*)malloc(mem_size);\n",
        "  float *h_cdata = (float*)malloc(mem_size);\n",
        "  float *h_tdata = (float*)malloc(mem_size);\n",
        "  float *gold    = (float*)malloc(mem_size);\n",
        "\n",
        "  float *d_idata, *d_cdata, *d_tdata;\n",
        "  checkCuda( cudaMalloc(&d_idata, mem_size) );\n",
        "  checkCuda( cudaMalloc(&d_cdata, mem_size) );\n",
        "  checkCuda( cudaMalloc(&d_tdata, mem_size) );\n",
        "\n",
        "  // check parameters and calculate execution configuration\n",
        "  if (nx % TILE_DIM || ny % TILE_DIM) {\n",
        "    printf(\"nx and ny must be a multiple of TILE_DIM\\n\");\n",
        "    goto error_exit;\n",
        "  }\n",
        "\n",
        "  if (TILE_DIM % BLOCK_ROWS) {\n",
        "    printf(\"TILE_DIM must be a multiple of BLOCK_ROWS\\n\");\n",
        "    goto error_exit;\n",
        "  }\n",
        "\n",
        "  // host\n",
        "  for (int j = 0; j < ny; j++)\n",
        "    for (int i = 0; i < nx; i++)\n",
        "      h_idata[j*nx + i] = j*nx + i;\n",
        "\n",
        "  // correct result for error checking\n",
        "  for (int j = 0; j < ny; j++)\n",
        "    for (int i = 0; i < nx; i++)\n",
        "      gold[j*nx + i] = h_idata[i*nx + j];\n",
        "\n",
        "  // device\n",
        "  checkCuda( cudaMemcpy(d_idata, h_idata, mem_size, cudaMemcpyHostToDevice) );\n",
        "\n",
        "  // events for timing\n",
        "  cudaEvent_t startEvent, stopEvent;\n",
        "  checkCuda( cudaEventCreate(&startEvent) );\n",
        "  checkCuda( cudaEventCreate(&stopEvent) );\n",
        "  float ms;\n",
        "\n",
        "  // ------------\n",
        "  // time kernels\n",
        "  // ------------\n",
        "  printf(\"%25s%25s\\n\", \"Routine\", \"Bandwidth (GB/s)\");\n",
        "\n",
        "  // ----\n",
        "  // copy\n",
        "  // ----\n",
        "  printf(\"%25s\", \"copy\");\n",
        "  checkCuda( cudaMemset(d_cdata, 0, mem_size) );\n",
        "  // warm up\n",
        "  copy<<<dimGrid, dimBlock>>>(d_cdata, d_idata);\n",
        "  checkCuda( cudaEventRecord(startEvent, 0) );\n",
        "  for (int i = 0; i < NUM_REPS; i++)\n",
        "     copy<<<dimGrid, dimBlock>>>(d_cdata, d_idata);\n",
        "  checkCuda( cudaEventRecord(stopEvent, 0) );\n",
        "  checkCuda( cudaEventSynchronize(stopEvent) );\n",
        "  checkCuda( cudaEventElapsedTime(&ms, startEvent, stopEvent) );\n",
        "  checkCuda( cudaMemcpy(h_cdata, d_cdata, mem_size, cudaMemcpyDeviceToHost) );\n",
        "  postprocess(h_idata, h_cdata, nx*ny, ms);\n",
        "\n",
        "  // -------------\n",
        "  // copySharedMem\n",
        "  // -------------\n",
        "  printf(\"%25s\", \"shared memory copy\");\n",
        "  checkCuda( cudaMemset(d_cdata, 0, mem_size) );\n",
        "  // warm up\n",
        "  copySharedMem<<<dimGrid, dimBlock>>>(d_cdata, d_idata);\n",
        "  checkCuda( cudaEventRecord(startEvent, 0) );\n",
        "  for (int i = 0; i < NUM_REPS; i++)\n",
        "     copySharedMem<<<dimGrid, dimBlock>>>(d_cdata, d_idata);\n",
        "  checkCuda( cudaEventRecord(stopEvent, 0) );\n",
        "  checkCuda( cudaEventSynchronize(stopEvent) );\n",
        "  checkCuda( cudaEventElapsedTime(&ms, startEvent, stopEvent) );\n",
        "  checkCuda( cudaMemcpy(h_cdata, d_cdata, mem_size, cudaMemcpyDeviceToHost) );\n",
        "  postprocess(h_idata, h_cdata, nx * ny, ms);\n",
        "\n",
        "  // --------------\n",
        "  // transposeNaive\n",
        "  // --------------\n",
        "  printf(\"%25s\", \"naive transpose\");\n",
        "  checkCuda( cudaMemset(d_tdata, 0, mem_size) );\n",
        "  // warmup\n",
        "  transposeNaive<<<dimGrid, dimBlock>>>(d_tdata, d_idata);\n",
        "  checkCuda( cudaEventRecord(startEvent, 0) );\n",
        "  for (int i = 0; i < NUM_REPS; i++)\n",
        "     transposeNaive<<<dimGrid, dimBlock>>>(d_tdata, d_idata);\n",
        "  checkCuda( cudaEventRecord(stopEvent, 0) );\n",
        "  checkCuda( cudaEventSynchronize(stopEvent) );\n",
        "  checkCuda( cudaEventElapsedTime(&ms, startEvent, stopEvent) );\n",
        "  checkCuda( cudaMemcpy(h_tdata, d_tdata, mem_size, cudaMemcpyDeviceToHost) );\n",
        "  postprocess(gold, h_tdata, nx * ny, ms);\n",
        "\n",
        "  // ------------------\n",
        "  // transposeCoalesced\n",
        "  // ------------------\n",
        "  printf(\"%25s\", \"coalesced transpose\");\n",
        "  checkCuda( cudaMemset(d_tdata, 0, mem_size) );\n",
        "  // warmup\n",
        "  transposeCoalesced<<<dimGrid, dimBlock>>>(d_tdata, d_idata);\n",
        "  checkCuda( cudaEventRecord(startEvent, 0) );\n",
        "  for (int i = 0; i < NUM_REPS; i++)\n",
        "     transposeCoalesced<<<dimGrid, dimBlock>>>(d_tdata, d_idata);\n",
        "  checkCuda( cudaEventRecord(stopEvent, 0) );\n",
        "  checkCuda( cudaEventSynchronize(stopEvent) );\n",
        "  checkCuda( cudaEventElapsedTime(&ms, startEvent, stopEvent) );\n",
        "  checkCuda( cudaMemcpy(h_tdata, d_tdata, mem_size, cudaMemcpyDeviceToHost) );\n",
        "  postprocess(gold, h_tdata, nx * ny, ms);\n",
        "\n",
        "  // ------------------------\n",
        "  // transposeNoBankConflicts\n",
        "  // ------------------------\n",
        "  printf(\"%25s\", \"conflict-free transpose\");\n",
        "  checkCuda( cudaMemset(d_tdata, 0, mem_size) );\n",
        "  // warmup\n",
        "  transposeNoBankConflicts<<<dimGrid, dimBlock>>>(d_tdata, d_idata);\n",
        "  checkCuda( cudaEventRecord(startEvent, 0) );\n",
        "  for (int i = 0; i < NUM_REPS; i++)\n",
        "     transposeNoBankConflicts<<<dimGrid, dimBlock>>>(d_tdata, d_idata);\n",
        "  checkCuda( cudaEventRecord(stopEvent, 0) );\n",
        "  checkCuda( cudaEventSynchronize(stopEvent) );\n",
        "  checkCuda( cudaEventElapsedTime(&ms, startEvent, stopEvent) );\n",
        "  checkCuda( cudaMemcpy(h_tdata, d_tdata, mem_size, cudaMemcpyDeviceToHost) );\n",
        "  postprocess(gold, h_tdata, nx * ny, ms);\n",
        "\n",
        "error_exit:\n",
        "  // cleanup\n",
        "  checkCuda( cudaEventDestroy(startEvent) );\n",
        "  checkCuda( cudaEventDestroy(stopEvent) );\n",
        "  checkCuda( cudaFree(d_tdata) );\n",
        "  checkCuda( cudaFree(d_cdata) );\n",
        "  checkCuda( cudaFree(d_idata) );\n",
        "  free(h_idata);\n",
        "  free(h_tdata);\n",
        "  free(h_cdata);\n",
        "  free(gold);\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHGbV_8XoA8U",
        "outputId": "d4fe9d65-bcb4-4071-9362-a41f1c5bcc52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting transpose.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o /content/transpose /content/transpose.cu -lcurand"
      ],
      "metadata": {
        "id": "eQuMAyBgoMfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o /content/matrix-multiplication /content/matrix-multiplication.cu -lcurand"
      ],
      "metadata": {
        "id": "CiQUTtpDkPrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/matrix-multiplication && /content/transpose"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RA2hWiHcmVHR",
        "outputId": "8548f2b5-65b3-4f3e-c1f5-8e9f044074c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Device : Tesla T4\n",
            "Matrix size: 1024 1024, Block size: 32 8, Tile size: 32 32\n",
            "dimGrid: 32 32 1. dimBlock: 32 8 1\n",
            "                  Routine         Bandwidth (GB/s)\n",
            "                     copy              210.33\n",
            "       shared memory copy              225.02\n",
            "          naive transpose               44.37\n",
            "      coalesced transpose               74.80\n",
            "  conflict-free transpose              203.45\n"
          ]
        }
      ]
    }
  ]
}